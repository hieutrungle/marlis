{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TORCHDYNAMO_INLINE_INBUILT_NN_MODULES\"] = \"1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "# os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"  # to avoid memory fragmentation\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "from typing import Tuple, Callable, Dict, Optional, Union\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import wandb\n",
    "import torchinfo\n",
    "import importlib.resources\n",
    "import copy\n",
    "import pyrallis\n",
    "from tensordict import TensorDict, from_module, from_modules\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torchrl.data import ReplayBuffer, LazyMemmapStorage\n",
    "import traceback\n",
    "import saris\n",
    "from saris.utils import utils, pytorch_utils, running_mean\n",
    "from saris.drl.agents import sac\n",
    "\n",
    "from saris.drl.envs import register_envs\n",
    "\n",
    "register_envs()\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SCRIPT_DIR\"] = \"/home/hieule/research/saris\"\n",
    "os.environ[\"BLENDER_DIR\"] = \"/home/hieule/blender\"\n",
    "os.environ[\"SOURCE_DIR\"] = \"/home/hieule/research/saris\"\n",
    "os.environ[\"ASSETS_DIR\"] = \"/home/hieule/research/saris/local_assets\"\n",
    "os.environ[\"BLENDER_APP\"] = \"/home/hieule/blender/blender-3.3.14-linux-x64/blender\"\n",
    "os.environ[\"TMP_DIR\"] = \"/home/hieule/research/saris/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed: int = 0\n",
    "    ep_len: int = 1000\n",
    "    eval_ep_len: int = 1000\n",
    "    eval_seed: int = 0\n",
    "    env_id: str = \"wireless-sigmap-v0\"\n",
    "    sionna_config_file: str = \"/home/hieule/research/saris/configs/sionna_L_multi_users.yaml\"\n",
    "    num_envs:int = 2\n",
    "    name:str = \"sac\"\n",
    "    load_replay_buffer:str = \"/home/hieule/research/saris/local_assets/replay_buffers/SAC__L_shape_static__wireless-sigmap-v0__68763e89\"\n",
    "    buffer_size: int = int(80_000)\n",
    "    batch_size: int = 256\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(config, idx: int, eval_mode: bool) -> Callable:\n",
    "\n",
    "    def thunk() -> gym.Env:\n",
    "\n",
    "        seed = config.seed if not eval_mode else config.eval_seed\n",
    "        max_episode_steps = config.ep_len if not eval_mode else config.eval_ep_len\n",
    "        seed += idx\n",
    "        env = gym.make(\n",
    "            config.env_id,\n",
    "            idx=idx,\n",
    "            sionna_config_file=config.sionna_config_file,\n",
    "            log_string=config.name,\n",
    "            eval_mode=eval_mode,\n",
    "            seed=seed,\n",
    "            max_episode_steps=max_episode_steps,\n",
    "        )\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        env = gym.wrappers.TimeLimit(env, max_episode_steps=max_episode_steps)\n",
    "        # env = gym.wrappers.FlattenObservation(env)\n",
    "        env.action_space.seed(config.seed)\n",
    "        env.observation_space.seed(config.seed)\n",
    "\n",
    "        return env\n",
    "\n",
    "    return thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_obs(\n",
    "    flat_obs: torch.Tensor,\n",
    "    real_channel_rms: running_mean.RunningMeanStd,\n",
    "    imag_channel_rms: running_mean.RunningMeanStd,\n",
    "    epsilon: float = 1e-8,\n",
    "):\n",
    "    real_mean = real_channel_rms.mean.to(flat_obs.device)\n",
    "    real_var = real_channel_rms.var.to(flat_obs.device)\n",
    "    real_channel_len = real_channel_rms.mean.shape[0]\n",
    "    real_channels = flat_obs[..., :real_channel_len]\n",
    "    real_channels = (real_channels - real_mean) / torch.sqrt(real_var + epsilon)\n",
    "\n",
    "    imag_mean = imag_channel_rms.mean.to(flat_obs.device)\n",
    "    imag_var = imag_channel_rms.var.to(flat_obs.device)\n",
    "    imag_channel_len = imag_channel_rms.mean.shape[0]\n",
    "    imag_channels = flat_obs[..., real_channel_len : real_channel_len + imag_channel_len]\n",
    "    imag_channels = (imag_channels - imag_mean) / torch.sqrt(imag_var + epsilon)\n",
    "\n",
    "    pos = flat_obs[..., real_channel_len + imag_channel_len :]\n",
    "    flat_obs = torch.cat([real_channels, imag_channels, pos], dim=-1)\n",
    "    return flat_obs\n",
    "\n",
    "\n",
    "def update_channel_rmss(\n",
    "    flat_obs: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n",
    "    real_channel_rms: running_mean.RunningMeanStd,\n",
    "    imag_channel_rms: running_mean.RunningMeanStd,\n",
    "):\n",
    "    real_channel_len = np.prod(real_channel_rms.mean.shape)\n",
    "    real_channel_rms.update(flat_obs[..., :real_channel_len])\n",
    "    imag_channel_len = np.prod(imag_channel_rms.mean.shape)\n",
    "    imag_channel_rms.update(flat_obs[..., real_channel_len : real_channel_len + imag_channel_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieule/research/env_saris/lib/python3.10/site-packages/traitlets/__init__.py:28: DeprecationWarning: \n",
      "            Sentinel is not a public part of the traitlets API.\n",
      "            It was published by mistake, and may be removed in the future.\n",
      "            \n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [make_env(config, i, eval_mode=False) for i in range(config.num_envs)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create running meanstd for normalization\n",
    "real_channel_len = math.prod(envs.single_observation_space[0].shape)\n",
    "imag_channel_len = math.prod(envs.single_observation_space[1].shape)\n",
    "real_channel_rms = running_mean.RunningMeanStd(shape=(real_channel_len,))\n",
    "imag_channel_rms = running_mean.RunningMeanStd(shape=(imag_channel_len,))\n",
    "obs_rmss = (real_channel_rms, imag_channel_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RunningMeanStd(mean=tensor([0., 0., 0.,  ..., 0., 0., 0.]), var=tensor([1., 1., 1.,  ..., 1., 1., 1.]), count=1e-15),\n",
       " RunningMeanStd(mean=tensor([0., 0., 0.,  ..., 0., 0., 0.]), var=tensor([1., 1., 1.,  ..., 1., 1., 1.]), count=1e-15))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_rmss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_dir = \"/home/hieule/research/saris/local_assets/replay_buffers/SAC__L_shape_static__wireless-sigmap-v0__d8fa5bea\"\n",
    "rb = ReplayBuffer(\n",
    "    storage=LazyMemmapStorage(config.buffer_size, scratch_dir=rb_dir),\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "rb.loads(config.load_replay_buffer)\n",
    "\n",
    "stored_obs = []\n",
    "for i, data in enumerate(rb):\n",
    "    stored_obs.append(data[\"observations\"])\n",
    "    if i >= len(rb) - 1:\n",
    "        break\n",
    "stored_obs = np.concatenate(stored_obs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_stored_obs = np.asarray(rb.storage.get(\"observations\"))\n",
    "update_channel_rmss(torch.tensor(stored_obs), obs_rmss[0], obs_rmss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RunningMeanStd(mean=tensor([-8.4409e-08,  9.9712e-08, -1.2190e-07,  ...,  4.8128e-09,\n",
       "         -4.6164e-09,  4.4355e-09]), var=tensor([5.3593e-14, 7.5684e-14, 1.1504e-13,  ..., 4.6910e-15, 4.3194e-15,\n",
       "         3.9904e-15]), count=160.0),\n",
       " RunningMeanStd(mean=tensor([ 8.1348e-08, -9.6128e-08,  1.1751e-07,  ..., -1.9953e-09,\n",
       "          1.9012e-09, -1.8154e-09]), var=tensor([3.3745e-14, 4.6791e-14, 6.9376e-14,  ..., 3.1586e-15, 2.9083e-15,\n",
       "         2.6867e-15]), count=160.0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_rmss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_obs = []\n",
    "\n",
    "obs, _ = envs.reset()\n",
    "obs = np.concatenate([ob.reshape(ob.shape[0], -1) for ob in obs], axis=-1)\n",
    "stored_obs.append(obs)\n",
    "\n",
    "for _ in range(5):\n",
    "    actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
    "    next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
    "    obs = copy.deepcopy(next_obs)\n",
    "    obs = np.concatenate([ob.reshape(ob.shape[0], -1) for ob in obs], axis=-1)\n",
    "    stored_obs.append(obs)\n",
    "stored_obs = np.concatenate(stored_obs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_channel_rmss(torch.tensor(stored_obs), obs_rmss[0], obs_rmss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RunningMeanStd(mean=tensor([-8.0655e-08,  9.5228e-08, -1.1633e-07,  ...,  6.9872e-09,\n",
       "         -6.7038e-09,  6.4426e-09]), var=tensor([5.3297e-14, 7.5260e-14, 1.1439e-13,  ..., 4.5517e-15, 4.1913e-15,\n",
       "         3.8721e-15]), count=172.0),\n",
       " RunningMeanStd(mean=tensor([ 8.2770e-08, -9.7888e-08,  1.1980e-07,  ..., -2.4721e-09,\n",
       "          2.3606e-09, -2.2587e-09]), var=tensor([3.4917e-14, 4.8484e-14, 7.2024e-14,  ..., 3.0438e-15, 2.8027e-15,\n",
       "         2.5892e-15]), count=172.0))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_rmss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_channel_rmss(torch.tensor(stored_obs), obs_rmss[0], obs_rmss[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_saris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
